---
layout: paper

title: "TabNet: Attentive Interpretable Tabular Learning "
authors:
- Sercan O. Arik
- Tomas Pfister

venue: AAAI
year: 2021

link: https://arxiv.org/abs/1908.07442

abstract: "
We propose a novel high-performance and interpretable canonical deep tabular
data learning architecture, TabNet. TabNet uses sequential attention to choose
which features to reason from at each decision step, enabling interpretability
and more efficient learning as the learning capacity is used for the most
salient features. We demonstrate that TabNet outperforms other variants on a
wide range of non-performance-saturated tabular datasets and yields
interpretable feature attributions plus insights into its global behavior.
Finally, we demonstrate self-supervised learning for tabular data,
significantly improving performance when unlabeled data is abundant.
"

who_suggested: Richard Everson
status: suggested
---
- [AAAI 2021 talk (20min)](https://slideslive.com/38947902/)
- [pytorch implementation](https://github.com/dreamquark-ai/tabnet)
- [explainer video (50min)](https://www.youtube.com/watch?v=ysBaZO8YmX8)
